{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f011ea2f77b1131f",
   "metadata": {},
   "source": [
    "#  Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ff74ba441139d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "833d5295-6f0c-49bc-942d-22b253356eef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-24T10:49:42.104379Z",
     "start_time": "2024-08-24T10:49:38.080160Z"
    }
   },
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Load data\n",
    "df_train = pd.read_pickle('data/train_processed.pkl')\n",
    "df_test = pd.read_pickle('data/test_processed.pkl')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78dd096242190676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T22:02:18.474766Z",
     "start_time": "2024-08-09T22:02:18.433235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>shops_closed</th>\n",
       "      <th>winter_school_holidays</th>\n",
       "      <th>school_holidays</th>\n",
       "      <th>id</th>\n",
       "      <th>date_year</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_day</th>\n",
       "      <th>date_day_of_week</th>\n",
       "      <th>date_week_of_year</th>\n",
       "      <th>...</th>\n",
       "      <th>holiday_name_Memorial Day of the Republic</th>\n",
       "      <th>holiday_name_Memorial day of the 1956 Revolution</th>\n",
       "      <th>holiday_name_NaN</th>\n",
       "      <th>holiday_name_National Defense Day</th>\n",
       "      <th>holiday_name_New Years Day</th>\n",
       "      <th>holiday_name_Peace Festival in Augsburg</th>\n",
       "      <th>holiday_name_Reformation Day</th>\n",
       "      <th>holiday_name_State Foundation Day</th>\n",
       "      <th>holiday_name_Whit monday</th>\n",
       "      <th>holiday_name_Whit sunday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13681</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Brno_1_2024-05-08</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13678</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Prague_1_2024-05-08</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13679</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Prague_2_2024-05-08</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13684</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Prague_3_2024-05-08</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13419</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Brno_1_2024-04-01</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       holiday  shops_closed  winter_school_holidays  school_holidays  \\\n",
       "13681        1             1                       0                0   \n",
       "13678        1             1                       0                0   \n",
       "13679        1             1                       0                0   \n",
       "13684        1             1                       0                0   \n",
       "13419        1             1                       0                0   \n",
       "\n",
       "                        id  date_year  date_month  date_day  date_day_of_week  \\\n",
       "13681    Brno_1_2024-05-08       2024           5         8                 2   \n",
       "13678  Prague_1_2024-05-08       2024           5         8                 2   \n",
       "13679  Prague_2_2024-05-08       2024           5         8                 2   \n",
       "13684  Prague_3_2024-05-08       2024           5         8                 2   \n",
       "13419    Brno_1_2024-04-01       2024           4         1                 0   \n",
       "\n",
       "       date_week_of_year  ...  holiday_name_Memorial Day of the Republic  \\\n",
       "13681                 19  ...                                        0.0   \n",
       "13678                 19  ...                                        0.0   \n",
       "13679                 19  ...                                        0.0   \n",
       "13684                 19  ...                                        0.0   \n",
       "13419                 14  ...                                        0.0   \n",
       "\n",
       "       holiday_name_Memorial day of the 1956 Revolution  holiday_name_NaN  \\\n",
       "13681                                               0.0               0.0   \n",
       "13678                                               0.0               0.0   \n",
       "13679                                               0.0               0.0   \n",
       "13684                                               0.0               0.0   \n",
       "13419                                               0.0               0.0   \n",
       "\n",
       "       holiday_name_National Defense Day  holiday_name_New Years Day  \\\n",
       "13681                                0.0                         0.0   \n",
       "13678                                0.0                         0.0   \n",
       "13679                                0.0                         0.0   \n",
       "13684                                0.0                         0.0   \n",
       "13419                                0.0                         0.0   \n",
       "\n",
       "       holiday_name_Peace Festival in Augsburg  holiday_name_Reformation Day  \\\n",
       "13681                                      0.0                           0.0   \n",
       "13678                                      0.0                           0.0   \n",
       "13679                                      0.0                           0.0   \n",
       "13684                                      0.0                           0.0   \n",
       "13419                                      0.0                           0.0   \n",
       "\n",
       "       holiday_name_State Foundation Day  holiday_name_Whit monday  \\\n",
       "13681                                0.0                       0.0   \n",
       "13678                                0.0                       0.0   \n",
       "13679                                0.0                       0.0   \n",
       "13684                                0.0                       0.0   \n",
       "13419                                0.0                       0.0   \n",
       "\n",
       "       holiday_name_Whit sunday  \n",
       "13681                       0.0  \n",
       "13678                       0.0  \n",
       "13679                       0.0  \n",
       "13684                       0.0  \n",
       "13419                       0.0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61a1de9b3909766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T22:02:18.998710Z",
     "start_time": "2024-08-09T22:02:18.838709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\n# Reconstruct the date column\\ndf_train = df_train.rename(columns={'date_year': 'year', 'date_month': 'month', 'date_day': 'day'})\\ndf_test = df_test.rename(columns={'date_year': 'year', 'date_month': 'month', 'date_day': 'day'})\\n\\ndf_train['date'] = pd.to_datetime(df_train[['year', 'month', 'day']])\\ndf_test['date'] = pd.to_datetime(df_test[['year', 'month', 'day']])\\n\\n# Restore the original column names\\ndf_train = df_train.rename(columns={'year': 'date_year', 'month': 'date_month', 'day': 'date_day'})\\ndf_test = df_test.rename(columns={'year': 'date_year', 'month': 'date_month', 'day': 'date_day'})\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "# Reconstruct the date column\n",
    "df_train = df_train.rename(columns={'date_year': 'year', 'date_month': 'month', 'date_day': 'day'})\n",
    "df_test = df_test.rename(columns={'date_year': 'year', 'date_month': 'month', 'date_day': 'day'})\n",
    "\n",
    "df_train['date'] = pd.to_datetime(df_train[['year', 'month', 'day']])\n",
    "df_test['date'] = pd.to_datetime(df_test[['year', 'month', 'day']])\n",
    "\n",
    "# Restore the original column names\n",
    "df_train = df_train.rename(columns={'year': 'date_year', 'month': 'date_month', 'day': 'date_day'})\n",
    "df_test = df_test.rename(columns={'year': 'date_year', 'month': 'date_month', 'day': 'date_day'})\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e419474-9a35-4b5f-8554-b6e091e7d57d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T22:02:18.592981Z",
     "start_time": "2024-08-09T22:02:18.540420Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scaling features\n",
    "features_to_scale = [\n",
    "    'date_year', 'date_month', 'date_day', 'date_day_of_week', 'date_day_of_year',\n",
    "    'date_week_of_year', 'date_quarter', 'month_sin', 'month_cos', \n",
    "    'day_sin', 'day_cos', \n",
    "    # 'lag_7_working', 'lag_14_working', 'lag_21_working', \n",
    "    # 'lag_28_working', 'rolling_mean_7_working', 'rolling_mean_14_working',\n",
    "    # 'rolling_mean_21_working', 'rolling_mean_28_working'\n",
    "]\n",
    "feature_scaler = StandardScaler()\n",
    "df_train[features_to_scale] = feature_scaler.fit_transform(df_train[features_to_scale])\n",
    "df_test[features_to_scale] = feature_scaler.transform(df_test[features_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb39b1393fe6e79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T22:02:18.738336Z",
     "start_time": "2024-08-09T22:02:18.718340Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "X = df_train.drop(columns=['orders'])\n",
    "y = df_train['orders']\n",
    "X_pred = df_test.drop(columns=['id'])\n",
    "ids = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de72ffe9-8feb-422c-9c1f-266770268122",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T22:02:19.040017Z",
     "start_time": "2024-08-09T22:02:19.035377Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tried training seperate models for warehouses but didn't get improvement on score\n",
    "# warehouse_cols_order = [\n",
    "#     'warehouse_Prague_1', 'warehouse_Brno_1', 'warehouse_Prague_2', \n",
    "#     'warehouse_Prague_3', 'warehouse_Munich_1', 'warehouse_Frankfurt_1', \n",
    "#     'warehouse_Budapest_1'\n",
    "# ]\n",
    "# \n",
    "# # Prepare data for modeling\n",
    "# X_train_list = [df_train[df_train[col] == 1].drop(columns=warehouse_cols_order + ['orders']) for col in warehouse_cols_order]\n",
    "# y_train_list = [df_train[df_train[col] == 1]['orders'] for col in warehouse_cols_order]\n",
    "# X_test_list = [df_test[df_test[col] == 1].drop(columns=warehouse_cols_order + ['id']) for col in warehouse_cols_order]\n",
    "# ids_list = [df_test[df_test[col] == 1]['id'] for col in warehouse_cols_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e12621ab-3c74-4f89-97fd-5b35536430af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T22:02:19.321861Z",
     "start_time": "2024-08-09T22:02:19.269981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: cbr\n",
      "Training MAPE: 0.017921237333216013\n",
      "Validation MAPE: 0.0338973646597381\n",
      "==========================\n",
      "Model: hgbr\n",
      "Training MAPE: 0.017566420788738213\n",
      "Validation MAPE: 0.035766979143804424\n",
      "==========================\n",
      "Model: xgbr\n",
      "Training MAPE: 0.009456837428049092\n",
      "Validation MAPE: 0.0363445090117793\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models and parameter distributions (here, parameters of extensive hp tuning are used)\n",
    "models = {\n",
    "    'cbr': (CatBoostRegressor(verbose=False, iterations=10000, depth=4, learning_rate=0.1, l2_leaf_reg=0.1), {\n",
    "    }),\n",
    "    'hgbr': (HistGradientBoostingRegressor(max_iter=10000, learning_rate=0.1, max_depth=4, l2_regularization=1), {\n",
    "    }),\n",
    "    'xgbr': (XGBRegressor(n_estimators=10000, learning_rate=0.1, max_depth=4, reg_lambda=1), {\n",
    "    })\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "df_model_predictions = pd.DataFrame()\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for name, (model, dist) in models.items():\n",
    "    rscv = RandomizedSearchCV(model, param_distributions=dist, n_iter=1, scoring='neg_mean_absolute_percentage_error', n_jobs=-1, cv=kfold, random_state=42)\n",
    "    search = rscv.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions on validation data\n",
    "    y_val_pred = rscv.predict(X_val)\n",
    "    val_mape = mean_absolute_percentage_error(y_val, y_val_pred)\n",
    "    \n",
    "    # Predictions on training data\n",
    "    y_train_pred = rscv.predict(X_train)\n",
    "    train_mape = mean_absolute_percentage_error(y_train, y_train_pred)\n",
    "    \n",
    "    print(f'Model: {name}')\n",
    "    print(f'Training MAPE: {train_mape}')\n",
    "    print(f'Validation MAPE: {val_mape}')\n",
    "    print('==========================')\n",
    "\n",
    "for name, (model, dist) in models.items():\n",
    "    rscv = RandomizedSearchCV(model, param_distributions=dist, n_iter=1, scoring='neg_mean_absolute_percentage_error', n_jobs=-1, cv=kfold, random_state=42)\n",
    "    search = rscv.fit(X, y)\n",
    "    \n",
    "    # Predictions on test data\n",
    "    y_pred = rscv.predict(X_pred)\n",
    "    df_model_predictions[name] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ca1411d982552bd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T22:06:10.643562Z",
     "start_time": "2024-08-09T22:02:28.751387Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/ml-training-2/venv/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: xgbr\n",
      "MAPE: 0.03558733591983194\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/ml-training-2/venv/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: cbr\n",
      "MAPE: 0.035465007079825764\n",
      "==========================\n",
      "Model: gbr\n",
      "MAPE: 0.0357215977655198\n",
      "==========================\n",
      "Model: hgbr\n",
      "MAPE: 0.0350670563714717\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "''' Old Implementation for lag and rolling features\n",
    "\n",
    "# Train and evaluate models\n",
    "df_model_predictions = pd.DataFrame()\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=429)\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, (model, dist) in models.items():\n",
    "    rscv = RandomizedSearchCV(model, param_distributions=dist, n_iter=200, scoring='neg_mean_absolute_percentage_error', n_jobs=28, cv=kfold, random_state=42)\n",
    "    search = rscv.fit(X, y)\n",
    "    best_model = search.best_estimator_\n",
    "    \n",
    "    # Initialize predictions DataFrame\n",
    "    df_test_predictions = df_test.copy()\n",
    "    \n",
    "    # Identify warehouse columns\n",
    "    warehouse_cols = [\n",
    "        'warehouse_Brno_1', 'warehouse_Budapest_1', 'warehouse_Frankfurt_1',\n",
    "        'warehouse_Munich_1', 'warehouse_Prague_1', 'warehouse_Prague_2', 'warehouse_Prague_3'\n",
    "    ]\n",
    "    \n",
    "    # Iterate over each warehouse\n",
    "    for warehouse_col in warehouse_cols:\n",
    "        \n",
    "        # Filter the test data for the current warehouse\n",
    "        df_warehouse_test = df_test_predictions[df_test_predictions[warehouse_col] == 1].copy()\n",
    "        \n",
    "        # Get corresponding training data for the current warehouse\n",
    "        df_warehouse_train = df_train[df_train[warehouse_col] == 1].copy()\n",
    "        \n",
    "        # Concatenate train and test data to ensure continuity\n",
    "        df_warehouse_combined = pd.concat([df_warehouse_train, df_warehouse_test], ignore_index=True)\n",
    "        \n",
    "        # Sort by date\n",
    "        df_warehouse_combined = df_warehouse_combined.sort_values('date')\n",
    "        \n",
    "        # Calculate initial lag and rolling features\n",
    "        def calculate_lag_and_rolling_features(df):\n",
    "            for lag in [7, 14, 21, 28]:\n",
    "                df[f'lag_{lag}_working'] = df['orders'].shift(lag)\n",
    "            for window in [7, 14, 21, 28]:\n",
    "                df[f'rolling_mean_{window}_working'] = df['orders'].rolling(window).mean()\n",
    "            return df\n",
    "        \n",
    "        df_warehouse_combined = calculate_lag_and_rolling_features(df_warehouse_combined)\n",
    "        \n",
    "        # Fill NaN values in lag and rolling features with -1\n",
    "        lag_features = [f'lag_{lag}_working' for lag in [7, 14, 21, 28]]\n",
    "        rolling_features = [f'rolling_mean_{window}_working' for window in [7, 14, 21, 28]]\n",
    "        df_warehouse_combined[lag_features + rolling_features] = df_warehouse_combined[lag_features + rolling_features].fillna(-1)\n",
    "        \n",
    "        # Iteratively predict and update features\n",
    "        for i in range(len(df_warehouse_train), len(df_warehouse_combined)):\n",
    "            # Predict the next order\n",
    "            X_next = df_warehouse_combined.iloc[i:i+1].drop(columns=['id', 'orders', 'date'])\n",
    "            y_next_pred = best_model.predict(X_next)[0]\n",
    "            \n",
    "            # Update the DataFrame with the new prediction\n",
    "            df_warehouse_combined.at[i, 'orders'] = y_next_pred\n",
    "            \n",
    "            # Update lag and rolling features for the next prediction\n",
    "            for lag in [7, 14, 21, 28]:\n",
    "                if i + lag < len(df_warehouse_combined):\n",
    "                    df_warehouse_combined.at[i + lag, f'lag_{lag}_working'] = df_warehouse_combined['orders'].iloc[i]\n",
    "            \n",
    "            for window in [7, 14, 21, 28]:\n",
    "                if i + window < len(df_warehouse_combined):\n",
    "                    window_data = df_warehouse_combined['orders'].iloc[i+1:i+window+1]\n",
    "                    if not window_data.isna().all():\n",
    "                        df_warehouse_combined.at[i + window, f'rolling_mean_{window}_working'] = window_data.mean()\n",
    "        \n",
    "        # Align indices before updating df_test_predictions\n",
    "        test_indices = df_warehouse_test.index\n",
    "        combined_indices = df_warehouse_combined.index[len(df_warehouse_train):]\n",
    "        df_test_predictions.loc[test_indices, 'orders'] = df_warehouse_combined.loc[combined_indices, 'orders'].values\n",
    "    \n",
    "    # Store predictions for the model\n",
    "    df_model_predictions[name] = df_test_predictions['orders']\n",
    "    \n",
    "    # Print model performance\n",
    "    score = search.best_score_ * -1\n",
    "    print(f'Model: {name}\\nMAPE: {score}\\n==========================')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a8c79d74-0d4a-41c6-8ecf-9b9f29b9019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming df_model_predictions is your DataFrame\n",
    "# df_model_predictions_sorted = df_model_predictions.sort_values(by=['id'])\n",
    "# \n",
    "# # Group by 'id' and use first() to combine rows for each model type\n",
    "# df_combined = df_model_predictions_sorted.groupby(df_model_predictions_sorted.index).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0940a9b2-92dc-40cb-9006-88ed45fcb47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "435c9456-8d7b-4007-bb29-86bd7617f024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cbr</th>\n",
       "      <th>hgbr</th>\n",
       "      <th>xgbr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9319.817014</td>\n",
       "      <td>10298.813141</td>\n",
       "      <td>8905.837891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10226.274378</td>\n",
       "      <td>10955.450499</td>\n",
       "      <td>9677.518555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6607.920590</td>\n",
       "      <td>7361.713165</td>\n",
       "      <td>5811.672363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5753.572734</td>\n",
       "      <td>6577.110171</td>\n",
       "      <td>5117.410156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7262.061826</td>\n",
       "      <td>7073.643628</td>\n",
       "      <td>6655.518066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>6959.441056</td>\n",
       "      <td>6957.643964</td>\n",
       "      <td>6549.690918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>7150.867065</td>\n",
       "      <td>7043.421271</td>\n",
       "      <td>6867.246094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>8266.672757</td>\n",
       "      <td>7628.952972</td>\n",
       "      <td>7809.608887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>7619.185634</td>\n",
       "      <td>7160.413647</td>\n",
       "      <td>7000.818848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>7001.075648</td>\n",
       "      <td>6836.164956</td>\n",
       "      <td>6749.707520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              cbr          hgbr         xgbr\n",
       "0     9319.817014  10298.813141  8905.837891\n",
       "1    10226.274378  10955.450499  9677.518555\n",
       "2     6607.920590   7361.713165  5811.672363\n",
       "3     5753.572734   6577.110171  5117.410156\n",
       "4     7262.061826   7073.643628  6655.518066\n",
       "..            ...           ...          ...\n",
       "392   6959.441056   6957.643964  6549.690918\n",
       "393   7150.867065   7043.421271  6867.246094\n",
       "394   8266.672757   7628.952972  7809.608887\n",
       "395   7619.185634   7160.413647  7000.818848\n",
       "396   7001.075648   6836.164956  6749.707520\n",
       "\n",
       "[397 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_predictions.head(397)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b5c7774-225b-43ec-876f-5998991af94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cbr     0\n",
       "hgbr    0\n",
       "xgbr    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_predictions.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "95943b51-9871-41d5-a0d3-41fc8bab41bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predictions saved to 'data/model_predictions.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Save model predictions\n",
    "df_model_predictions.to_pickle('data/model_predictions.pkl')\n",
    "print(\"Model predictions saved to 'data/model_predictions.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b7026116fd7de90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_actual = target_scaler.inverse_transform(y_pred.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b90e1853de820255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different ensemble combinations\n",
    "ensemble_combinations = [\n",
    "    ['cbr', 'hgbr', 'xgbr'],\n",
    "    ['hgbr'],\n",
    "    ['cbr']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83427573d4ed6d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission_42 saved with models: cbr, hgbr, xgbr\n",
      "Submission_43 saved with models: hgbr\n",
      "Submission_44 saved with models: cbr\n",
      "All submissions have been saved.\n"
     ]
    }
   ],
   "source": [
    "# Create and save ensemble submissions\n",
    "for i, combination in enumerate(ensemble_combinations, 42):\n",
    "    ensemble_predictions = df_model_predictions[combination].mean(axis=1)\n",
    "    submission = pd.DataFrame({'id': df_test['id'].values, 'orders': ensemble_predictions})\n",
    "    submission.to_csv(f'data/submission_{i}.csv', index=False)\n",
    "    print(f\"Submission_{i} saved with models: {', '.join(combination)}\")\n",
    "    \n",
    "print(\"All submissions have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364400b-d8d3-4cc8-a24f-1254936325b5",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
